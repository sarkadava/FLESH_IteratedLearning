---
title: "Gillian stats start"
date: "2024-03-25"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
---

# Introduction

In this stats file, we answer questions about the iterated learning experiment conducted on the Long Night of Sciences.

# Questions

Part 1
- Does generation have an effect on gesture space used?
- Does generation have an effect on entropy used?
- Does generation have an effect on temporal variability used?
- Does Age and Extroversion have an effect on gesture space, enotrpy, and temporal variability? (See Model Four)

For part one, we test four different models for each of the first three questions. 
Model one uses a gaussian distribution and looks only at intercepts.
Model two uses a lognormal distribution and looks only at intercepts.
Model three uses a lognormal distribution and includes random effects
Model four uses a lognormal distribution and includes random effects and fixed effects of age and extroversion.

Part 2
- Does does a bigger diff in age mean greater distance between one gesture and another?
- Does does a bigger diff in extroversion mean greater distance between one gesture and another?
- Does does a bigger diff in num of languages mean greater distance between one gesture and another?


# Setting up the environment

```{r setup environment, echo=TRUE, message=FALSE, warning=FALSE}

library(here)
library(dplyr) # for data-wrangling
library(lme4)  # for linear mixed-effects models
library(tidyr)  # for reshaping data (if needed)
library(ggplot2)
library(tibble)
library(rcartocolor)

library(ggdag) # for dag
library(dagitty)

library(ggplot2) # bayesian stuff
library(patchwork)
library(bayesplot)
library(brms)
library(beepr)
library(bayestestR)
library(tidyverse)

# current folder (first go to session -> set working directory -> to source file location)
parentfolder <- dirname(getwd())

datasets      <- paste0(parentfolder, '/Gillian_stats/datasets/') # This line is different on mac and others
models        <- paste0(parentfolder, '/Gillian_stats/models/')
plots         <- paste0(parentfolder, '/Gillian_stats/plots/')


```

# use all available cores
```{r cores, include=FALSE, message=FALSE, warning=FALSE}

# use all available cores for parallel computing
options(mc.cores = parallel::detectCores())
```
# Loading in our data

```{r loading_data, echo=TRUE, message=FALSE, warning=FALSE}

data <- read_csv(paste0(datasets, "final_stats_dataframe_aggregated.csv"))
```

Here we look into structure of our data: what is distribution of gender, age, extroversion, number of languages for example

```{r h1 visualizing data, message=FALSE, warning=FALSE}
hist(data$Extroversion)
hist(data$Age)
hist(data$TotalLanguages)
```

Also here you want to make sure all columns are of types you need - so for example factorizing categorical variables etc.

```{r h1 factorizing, message=FALSE, warning=FALSE}

#data2$generation_number <- as.factor(data2$generation_number)
data$participantID <- as.factor(data$participantID)
data$chain_number <- as.factor(data$chain_number)
data$gesture <- as.factor(data$gesture)
data$Gender <- as.factor(data$Gender)

data$Age <- as.numeric(data$Age)
data$Extroversion <- as.numeric(data$Extroversion)
data$NumOfNativeLanguages <- as.numeric(data$NumOfNativeLanguages)

data$generation_number <- as.numeric(data$generation_number)
data$total_distance <- as.numeric(data$total_distance)
data$diff_in_age <- as.numeric(data$diff_in_age)
data$diff_in_extrovet <- as.numeric(data$diff_in_extrovet)

```
## Data wrangling

To have easier interpretation of the data, we will center the generation number. With that, our estimate of the intercept will always apply for generation in the middle. Otherwise, it would be estimate for the first generation

```{r}

data$generation_number_c <- data$generation_number - median(range(data$generation_number))
```
Below, we adjust all of the entropy data by a constant (half the value of the minimum value), so we don't have any zeros in our data. (This is reasonable because zero entropy doesn't make sense anyway).
```{r}
c <- min(data$total_body_entropy2Daggregated[data$total_body_entropy2Daggregated > 0]) / 2 # decide on a constant
data$entropy_shifted <- data$total_body_entropy2Daggregated + c  # Shift all values
c2 <-min(data$total_body_variability2Daggregated[data$total_body_variability2Daggregated > 0]) / 2
data$variability_shifted <- data$total_body_variability2Daggregated + c2
```

# Question One, part one: Generation v gesture space

Below, we start to focus on our first question (part one: gesture space)

1) We hypothesize that gesture space decreases as a function of generation.
First, we look at the distribution of the gesture space data.

Results: It seems to be that there is a lognormal distribution.
```{r}
hist(data$total_gesture_space2D)
```

Below, we look at how our first question is answered purely by the data. We plot generation vs total gesture space. 

Result analysis: Based on the graph below, it seems as if there is a tiny tiny increase across generations, but it is very hard to tell if there is any pattern at all.

```{r}

ggplot(data, aes(x = generation_number, y = total_gesture_space2D)) +
  geom_point(alpha = 0.5) +  # Scatter plot with transparency
  geom_smooth(method = "lm", color = "blue", se = TRUE) +  # Linear trend line with confidence interval
  labs(x = "Generation Number", 
       y = "total_gesture_space2D", 
       title = "Linear Relationship between Generation Number and Gesture space") +
  theme_minimal()

```
##We now test four different models to understand relation between generation and gesture space.

## Model 1 - intercept only

This is the model
```{r h1.m1 model, eval=FALSE, message=FALSE, warning=FALSE}

m1.gs <- brm(
  total_gesture_space2D ~ generation_number_c, 
  data = data,
  family = gaussian(),  # Normal distribution for continuous entropy
  chains = 4, iter = 2000, warmup = 1000, cores = 4
)

# Add criterions for later diagnostics
m1.gs <- add_criterion(m1.gs, criterion = c("loo", "waic"))

# Calculate also variance explained (R^2)
m1.gs_R2 <- bayes_R2(m1.gs)

# Save both as objects
saveRDS(m1.gs, file.path(models, "m1.gs.rds"))
saveRDS(m1.gs_R2, file.path(models, "m1.gs_R2.rds"))

beep(5)

```

Here we load the model so that we don't have to run the model again
```{r h1.m1 sum, echo=TRUE, message=FALSE, warning=FALSE}

m1.gs <- readRDS(file.path(models, "m1.gs.rds"))
m1.gs_R2 <- readRDS(file.path(models, "m1.gs_R2.rds"))


# Summary
summary(m1.gs)

```
Let's also check the visuals

```{r h1.m1 check, echo=TRUE, message=FALSE, warning=FALSE}

plot(m1.gs)
# make some comments of what you see - do you see nice hairy catterpillars?

plot(conditional_effects(m1.gs), points = TRUE)
# also here about what effect you see or not see

pp_check(m1.gs, type = "dens_overlay")
# how well does the model predict future data?

pp_check(m1.gs, type = "error_scatter_avg")
# how are the values correlated with residual error?

m1.gs_R2
# how much variance the model explains? 

```
Now we are not happy, because for example ppcheck reveals that...

As we inspected the outcome variable, we think that lognormal family could be maybe more appropriate. So we try it 

## Model 2 lognormal

```{r h1.m1 model, eval=FALSE, message=FALSE, warning=FALSE}

m2.gs <- brm(
  total_gesture_space2D ~ generation_number_c, 
  data = data,
  family = lognormal(),  # Here we change lognormal
  chains = 4, iter = 2000, warmup = 1000, cores = 4
)

# Add criterions for later diagnostics
m2.gs <- add_criterion(m2.gs, criterion = c("loo", "waic"))

# Calculate also variance explained (R^2)
m2.gs_R2 <- bayes_R2(m2.gs)

# Save both as objects
saveRDS(m2.gs, file.path(models, "m2.gs.rds"))
saveRDS(m2.gs_R2, file.path(models, "m2.gs_R2.rds"))


beep(5)

```
 
And we do the same procedure

```{r h1.m1 sum, echo=TRUE, message=FALSE, warning=FALSE}

m2.gs <- readRDS(file.path(models, "m2.gs.rds"))
m2.gs_R2 <- readRDS(file.path(models, "m2.gs_R2.rds"))


# Summary
summary(m2.gs)

```


Let's also check the visuals

```{r h1.m1 check, echo=TRUE, message=FALSE, warning=FALSE}

plot(m2.gs)
# comments

plot(conditional_effects(m2.gs), points = TRUE)
# We barely see any slope.

pp_check(m2.gs, type = "dens_overlay")
# Not a bad overlay

pp_check(m2.gs, type = "error_scatter_avg")
# There is a linear correlation it seems which is not good.

m2.gs_R2
# It only explains .7 percent of the data! Yikes!

```

We are still not acknowledging some structures of the data to the model. There is some variance coming from XYZ. So we want to add it into the model too

## Model 3 - lognormal with random effects

```{r h1.m1 model, eval=FALSE, message=FALSE, warning=FALSE}

m3.gs <- brm(
  total_gesture_space2D ~ generation_number_c + (1 | participantID) + (1 | gesture) + (1 | chain_number), 
  data = data,
  family = lognormal(),  # Normal distribution for continuous entropy
  chains = 4, iter = 4000, warmup = 2000, cores = 4
)

# Add criterions for later diagnostics
m3.gs <- add_criterion(m3.gs, criterion = c("loo", "waic"))

# Calculate also variance explained (R^2)
m3.gs_R2 <- bayes_R2(m3.gs)

# Save both as objects
saveRDS(m3.gs, file.path(models, "m3.gs.rds"))
saveRDS(m3.gs_R2, file.path(models, "m3.gs_R2.rds"))


beep(5)

```

And once again we do all over the whole procedure

```{r h1.m1 sum, echo=TRUE, message=FALSE, warning=FALSE}

m3.gs <- readRDS(file.path(models, "m3.gs.rds"))
m3.gs_R2 <- readRDS(file.path(models, "m3.gs_R2.rds"))


# Summary
summary(m3.gs)

```


Let's also check the visuals

```{r h1.m1 check, echo=TRUE, message=FALSE, warning=FALSE}

plot(m3.gs)

# I am unclear what I am supposed to see here

plot(conditional_effects(m3.gs), points = TRUE)
# I see almost no slope

pp_check(m3.gs, type = "dens_overlay")
# looks pretty accurate?

pp_check(m3.gs, type = "error_scatter_avg")
# some correlation, but it also looks like a blob a bit which is good!


m3.gs_R2
# explains 68.18 of the variance!

```

## MODEL FOUR: (Investigate other fixed effects)
In this model, we investigate the effects of Age, Extroversion, and Gender. Thus, we begin by plotting the relationships between them. 

Age:
```{r}

ggplot(data, aes(x = Age, y = total_gesture_space2D)) +
  geom_point(alpha = 0.5) +  # Scatter plot with transparency
  geom_smooth(method = "lm", color = "blue", se = TRUE) +  # Linear trend line with confidence interval
  labs(x = "Age", 
       y = "Gesture Space", 
       title = "Linear Relationship between Age and Gesture space") +
  theme_minimal()

```
Extroversion
```{r}

ggplot(data, aes(x = Extroversion, y = total_gesture_space2D)) +
  geom_point(alpha = 0.5) +  # Scatter plot with transparency
  geom_smooth(method = "lm", color = "blue", se = TRUE) +  # Linear trend line with confidence interval
  labs(x = "Extroversion", 
       y = "Gesture Space", 
       title = "Linear Relationship between Extroversion and Gesture space") +
  theme_minimal()

```
Gender - THIS IS THE WRONG TYPE OF PLOT MAYBE?
```{r}

ggplot(data, aes(x = Gender, y = total_gesture_space2D)) +
  geom_point(alpha = 0.5) +  # Scatter plot with transparency
  geom_smooth(method = "lm", color = "blue", se = TRUE) +  # Linear trend line with confidence interval
  labs(x = "Gender", 
       y = "Gesture Space", 
       title = "Linear Relationship between Extroversion and Gesture space") +
  theme_minimal()

```
#Models 4:
```{r h1.m1 model, eval=FALSE, message=FALSE, warning=FALSE}
# TRIED TO USE THIS MODEL WITH Z_SCORE AND IT DIDN"T GO WELL. kept it here just in case, but I don't use these variables in my model.
data$z_score_Age <- (data$Age - mean(data$Age, na.rm = TRUE)) / sd(data$Age, na.rm = TRUE)
data$z_score_Extroversion <- (data$Age - mean(data$Extroversion, na.rm = TRUE)) / sd(data$Extroversion, na.rm = TRUE)
```
```{r}

ggplot(data, aes(x = z_score_Age, y = total_gesture_space2D)) +
  geom_point(alpha = 0.5) +  # Scatter plot with transparency
  geom_smooth(method = "lm", color = "blue", se = TRUE) +  # Linear trend line with confidence interval
  labs(x = "Age", 
       y = "Gesture Space", 
       title = "Linear Relationship between Age and Gesture space") +
  theme_minimal()

```
```{r}

m4.gs <- brm(
  total_gesture_space2D ~ generation_number_c + Age + Extroversion + (1 | participantID) + (1 | gesture) + (1 | chain_number), 
  data = data,
  family = lognormal(),  # Normal distribution for continuous entropy
  chains = 4, iter = 2000, warmup = 1000, cores = 4, 
  control = list(adapt_delta = 0.99)
)

# Add criterions for later diagnostics
m4.gs <- add_criterion(m4.gs, criterion = c("loo", "waic"))

# Calculate also variance explained (R^2)
m4.gs_R2 <- bayes_R2(m4.gs)

# Save both as objects
saveRDS(m4.gs, file.path(models, "m4.gs.rds"))
saveRDS(m4.gs_R2, file.path(models, "m4.gs_R2.rds"))


beep(5)

m4.gs <- readRDS(file.path(models, "m4.gs.rds"))
m4.gs_R2 <- readRDS(file.path(models, "m4.gs_R2.rds"))


# Summary
summary(m4.gs)

```
Let's also check visuals
```{r h1.m1 check, echo=TRUE, message=FALSE, warning=FALSE}

plot(m4.gs)

# not totally sure how to interpret. 

plot(conditional_effects(m4.gs), points = TRUE)
#

pp_check(m4.gs, type = "dens_overlay")
# 

pp_check(m4.gs, type = "error_scatter_avg")
# 


m4.gs_R2
# explains 65.96 percent of the variance
```
# MODEL FIVE: includes gender and num of languages as a fixed variable. Also has save pars as true and control  

```{r}
m5.gs <- brm(
  total_gesture_space2D ~ generation_number_c + Age + Extroversion + Gender +NumOfNativeLanguages + (1 | participantID) + (1 | gesture) + (1 | chainID), 
  data = data,
  family = lognormal(),  # Normal distribution for continuous entropy
  chains = 4, iter = 2000, warmup = 1000, cores = 4,
  save_pars = save_pars(all = TRUE),
  control = list(adapt_delta = 0.99)
)

# Add criterions for later diagnostics
m5.gs <- add_criterion(m5.gs, criterion = c("loo", "waic"))

# Calculate also variance explained (R^2)
m5.gs_R2 <- bayes_R2(m4.gs)

# Save both as objects
saveRDS(m5.gs, file.path(models, "m5.gs.rds"))
saveRDS(m5.gs_R2, file.path(models, "m5.gs_R2.rds"))

beep(5)

m5.gs <- readRDS(file.path(models, "m5.gs.rds"))
m5.gs_R2 <- readRDS(file.path(models, "m5.gs_R2.rds"))


# Summary
summary(m5.gs)

```

```{r}
plot(m5.gs)
# make some comments of what you see - do you see nice hairy catterpillars?

plot(conditional_effects(m5.gs), points = TRUE)
# also here about what effect you see or not see

pp_check(m5.gs, type = "dens_overlay")
# how well does the model predict future data?

pp_check(m5.gs, type = "error_scatter_avg")
# how are the values correlated with residual error?

m5.gs_R2
# accounts for 66.4 percent of the variance
```
# Question One, part two: Generation v Entropy
Here we continue our first question (part two: entropy)

1) We hypothesize that entropy decreases as a function of generation.

Here we look at how the question is answered purely by the data:

```{r}

ggplot(data, aes(x = generation_number, y = entropy_shifted)) +
  geom_point(alpha = 0.5) +  # Scatter plot with transparency
  geom_smooth(method = "lm", color = "blue", se = TRUE) +  # Linear trend line with confidence interval
  labs(x = "Generation Number", 
       y = "entropy_shifted", 
       title = "Linear Relationship between Generation Number and Gesture space") +
  theme_minimal()

```

Look at the distribution of the outcome:

```{r}

hist(data$entropy_shifted)

```

## Model 1 - intercept only

This is the model
```{r h1.m1 model, eval=FALSE, message=FALSE, warning=FALSE}

m1.et <- brm(
  entropy_shifted ~ generation_number_c, 
  data = data,
  family = gaussian(),  # Normal distribution for continuous entropy
  chains = 4, iter = 2000, warmup = 1000, cores = 4
)

# Add criterions for later diagnostics
m1.et <- add_criterion(m1.et, criterion = c("loo", "waic"))

# Calculate also variance explained (R^2)
m1.et_R2 <- bayes_R2(m1.et)

# Save both as objects
saveRDS(m1.et, file.path(models, "m1.et.rds"))
saveRDS(m1.et_R2, file.path(models, "m1.et_R2.rds"))

beep(5)

```

Here we load the model so that we don't have to run the model again
```{r h1.m1 sum, echo=TRUE, message=FALSE, warning=FALSE}

m1.et <- readRDS(file.path(models, "m1.et.rds"))
m1.et_R2 <- readRDS(file.path(models, "m1.et_R2.rds"))


# Summary
summary(m1.et)

```


Let's also check the visuals

```{r h1.m1 check, echo=TRUE, message=FALSE, warning=FALSE}

plot(m1.et)
# make some comments of what you see - do you see nice hairy catterpillars?

plot(conditional_effects(m1.et), points = TRUE)
# also here about what effect you see or not see

pp_check(m1.et, type = "dens_overlay")
# how well does the model predict future data?

pp_check(m1.et, type = "error_scatter_avg")
# how are the values correlated with residual error?

m1.et_R2
# how much variance the model explains? 

```
Now we are not happy, because for example ppcheck reveals that...

As we inspected the outcome variable, we think that lognormal family could be maybe more appropriate. So we try it 

## Model 2 lognormal - it actually doesn't make a difference whether I put log_entropy_shifted here or just entropy_shifted

```{r h1.m1 model, eval=FALSE, message=FALSE, warning=FALSE}

min_value <- min(data$entropy_shifted)
print(min_value)
offset <- abs(min_value) + 1e-3
print(offset)# Ensure all values are strictly positive
data$entropy_shifted_shifted <- data$entropy_shifted + offset
summary(data$entropy_shifted_shifted)
min(data$entropy_shifted_shifted)

offset <- abs(min_value) + 1  # Ensures all values are at least 1
data$entropy_shifted_shifted <- data$entropy_shifted + offset
data$log_entropy_shifted <- log(data$entropy_shifted_shifted)

data$log_entropy_shifted <- log(data$entropy_shifted_shifted)
min(data$log_entropy_shifted)

m2.et <- brm(
  entropy_shifted ~ generation_number_c, 
  data = data,
  family = lognormal(),  # Here we change lognormal
  chains = 4, iter = 2000, warmup = 1000, cores = 4
)


# Add criterions for later diagnostics
m2.et <- add_criterion(m2.et, criterion = c("loo", "waic"))

# Calculate also variance explained (R^2)
m2.et_R2 <- bayes_R2(m2.et)

# Save both as objects
saveRDS(m2.et, file.path(models, "m2.et.rds"))
saveRDS(m2.et_R2, file.path(models, "m2.et_R2.rds"))


beep(5)

```
 
And we do the same procedure

```{r h1.m1 sum, echo=TRUE, message=FALSE, warning=FALSE}

m2.et <- readRDS(file.path(models, "m2.et.rds"))
m2.et_R2 <- readRDS(file.path(models, "m2.et_R2.rds"))


# Summary
summary(m2.et)

```


Let's also check the visuals

```{r h1.m1 check, echo=TRUE, message=FALSE, warning=FALSE}

plot(m2.et)
# comments

plot(conditional_effects(m2.et), points = TRUE)
# comments

pp_check(m2.et, type = "dens_overlay")
# comments

pp_check(m2.et, type = "error_scatter_avg")
# comments

m2.et_R2
# comments

```

We are still not acknowledging some structures of the data to the model. There is some variance coming from XYZ. So we want to add it into the model too

## Model 3 - lognormal with random effects 

```{r h1.m1 model, eval=FALSE, message=FALSE, warning=FALSE}

m3.et <- brm(
  entropy_shifted ~ generation_number_c + (1 | participantID) + (1 | gesture) + (1 | chain_number), 
  data = data,
  family = lognormal,  # (I tested gamma and gaussian and they didn't give me better results)
  chains = 4, iter = 4000, warmup = 2000, cores = 4
)

# Add criterions for later diagnostics
m3.et <- add_criterion(m3.et, criterion = c("loo", "waic"))

# Calculate also variance explained (R^2)
m3.et_R2 <- bayes_R2(m3.et)

# Save both as objects
saveRDS(m3.et, file.path(models, "m3.et.rds"))
saveRDS(m3.et_R2, file.path(models, "m3.et_R2.rds"))


beep(5)

```

And once again we do all over the whole procedure

```{r h1.m1 sum, echo=TRUE, message=FALSE, warning=FALSE}

m3.et <- readRDS(file.path(models, "m3.et.rds"))
m3.et_R2 <- readRDS(file.path(models, "m3.et_R2.rds"))


# Summary
summary(m3.et)

```



Let's also check the visuals

```{r h1.m1 check, echo=TRUE, message=FALSE, warning=FALSE}

plot(m3.et)

#

plot(conditional_effects(m3.et), points = TRUE)
#

pp_check(m3.et, type = "dens_overlay")
# 

pp_check(m3.et, type = "error_scatter_avg")
# 


m3.et_R2
#  

```
## MODEL FOUR: (Investigate other fixed effects)
In this model, we investigate the effects of Age, Extroversion, and Gender. Thus, we begin by plotting the relationships between them. 

Age:
```{r}

ggplot(data, aes(x = Age, y = entropy_shifted)) +
  geom_point(alpha = 0.5) +  # Scatter plot with transparency
  geom_smooth(method = "lm", color = "blue", se = TRUE) +  # Linear trend line with confidence interval
  labs(x = "Age", 
       y = "Entropy", 
       title = "Linear Relationship between Age and Entropy") +
  theme_minimal()

```
Extroversion
```{r}

ggplot(data, aes(x = Extroversion, y = entropy_shifted)) +
  geom_point(alpha = 0.5) +  # Scatter plot with transparency
  geom_smooth(method = "lm", color = "blue", se = TRUE) +  # Linear trend line with confidence interval
  labs(x = "Extroversion", 
       y = "Entropy", 
       title = "Linear Relationship between Extroversion and Entropy") +
  theme_minimal()

```
Gender
```{r}

ggplot(data, aes(x = Gender, y = entropy_shifted)) +
  geom_point(alpha = 0.5) +  # Scatter plot with transparency
  geom_smooth(method = "lm", color = "blue", se = TRUE) +  # Linear trend line with confidence interval
  labs(x = "Gender", 
       y = "Entropy", 
       title = "Linear Relationship between Gender and Entropy") +
  theme_minimal()

```

```{r h1.m1 model, eval=FALSE, message=FALSE, warning=FALSE}

m4.et <- brm(
  entropy_shifted ~ generation_number_c + Age + Extroversion + (1 | participantID) + (1 | gesture) + (1 | chain_number), 
  data = data,
  family = lognormal(),  # Normal distribution for continuous entropy
  chains = 4, iter = 2000, warmup = 1000, cores = 4
)

# Add criterions for later diagnostics
m4.et <- add_criterion(m4.et, criterion = c("loo", "waic"))

# Calculate also variance explained (R^2)
m4.et_R2 <- bayes_R2(m4.et)

# Save both as objects
saveRDS(m4.et, file.path(models, "m4.et.rds"))

saveRDS(m4.et_R2, file.path(models, "m4.et_R2.rds"))


beep(5)

m4.et <- readRDS(file.path(models, "m4.et.rds"))
m4.et_R2 <- readRDS(file.path(models, "m4.et_R2.rds"))


# Summary
summary(m4.et)

```
Let's also check visuals
```{r h1.m1 check, echo=TRUE, message=FALSE, warning=FALSE}

plot(m4.et)

#

plot(conditional_effects(m4.et), points = TRUE)
#

pp_check(m4.et, type = "dens_overlay")
# 

pp_check(m4.et, type = "error_scatter_avg")
# 


m4.et_R2
```
```{r}
m5.et <- brm(
  entropy_shifted ~ generation_number_c + Age + Extroversion + Gender + NumOfNativeLanguages + (1 | participantID) + (1 | gesture) + (1 | chain_number), 
  data = data,
  family = lognormal(),  # Normal distribution for continuous entropy
  chains = 4, iter = 2000, warmup = 1000, cores = 4
)

# Add criterions for later diagnostics
m5.et <- add_criterion(m5.et, criterion = c("loo", "waic"))

# Calculate also variance explained (R^2)
m5.et_R2 <- bayes_R2(m4.et)

# Save both as objects
saveRDS(m5.et, file.path(models, "m5.et.rds"))

saveRDS(m5.et_R2, file.path(models, "m5.et_R2.rds"))


beep(5)

m5.et <- readRDS(file.path(models, "m5.et.rds"))
m5.et_R2 <- readRDS(file.path(models, "m5.et_R2.rds"))


# Summary
summary(m5.et)

```
# Question One, part three: Generation v Temporal Variability
Here we continue our first question (part three: temporal variability)

1) We hypothesize that temporal variability decreases as a function of generation.

Here we look at how the question is answered purely by the data:

```{r}

ggplot(data, aes(x = generation_number, y = total_body_variability2D)) +
  geom_point(alpha = 0.5) +  # Scatter plot with transparency
  geom_smooth(method = "lm", color = "blue", se = TRUE) +  # Linear trend line with confidence interval
  labs(x = "Generation Number", 
       y = "Temporal Variability", 
       title = "Linear Relationship between Generation Number and Temporal Variability") +
  theme_minimal()

```

Look at the distribution of the outcome:

```{r}

hist(data$total_body_variability2D)

```

## Model 1 - intercept only

This is the model
```{r h1.m1 model, eval=FALSE, message=FALSE, warning=FALSE}

m1.tv <- brm(
  variability_shifted ~ generation_number_c, 
  data = data,
  family = gaussian(),  # Normal distribution for continuous entropy
  chains = 4, iter = 2000, warmup = 1000, cores = 4
)

# Add criterions for later diagnostics
m1.tv <- add_criterion(m1.et, criterion = c("loo", "waic"))

# Calculate also variance explained (R^2)
m1.tv_R2 <- bayes_R2(m1.tv)

# Save both as objects
saveRDS(m1.tv, file.path(models, "m1.tv.rds"))
saveRDS(m1.tv_R2, file.path(models, "m1.tv_R2.rds"))

beep(5)

```

Here we load the model so that we don't have to run the model again
```{r h1.m1 sum, echo=TRUE, message=FALSE, warning=FALSE}

m1.tv <- readRDS(file.path(models, "m1.tv.rds"))
m1.tv_R2 <- readRDS(file.path(models, "m1.tv_R2.rds"))


# Summary
summary(m1.tv)

```


Let's also check the visuals

```{r h1.m1 check, echo=TRUE, message=FALSE, warning=FALSE}

plot(m1.tv)
# make some comments of what you see - do you see nice hairy catterpillars?

plot(conditional_effects(m1.tv), points = TRUE)
# I do not see any effect of generation on temporal variability

pp_check(m1.tv, type = "dens_overlay")
# Does not predict future data well. 

pp_check(m1.tv, type = "error_scatter_avg")
# High correlation between values and residentual error which is bad.

m1.tv_R2
# It only explains .8 of the variance

```
Now we are not happy, because for example ppcheck reveals that...

As we inspected the outcome variable, we think that lognormal family could be maybe more appropriate. So we try it 

## Model 2 lognormal

```{r h1.m1 model, eval=FALSE, message=FALSE, warning=FALSE}

m2.tv <- brm(
  variability_shifted ~ generation_number_c, 
  data = data,
  family = lognormal(),  # Here we change lognormal
  chains = 4, iter = 2000, warmup = 1000, cores = 4
)

# Add criterions for later diagnostics
m2.tv <- add_criterion(m2.tv, criterion = c("loo", "waic"))

# Calculate also variance explained (R^2)
m2.tv_R2 <- bayes_R2(m2.tv)

# Save both as objects
saveRDS(m2.tv, file.path(models, "m2.tv.rds"))
saveRDS(m2.tv_R2, file.path(models, "m2.tv_R2.rds"))


beep(5)

```
 
And we do the same procedure

```{r h1.m1 sum, echo=TRUE, message=FALSE, warning=FALSE}

m2.tv <- readRDS(file.path(models, "m2.tv.rds"))
m2.tv_R2 <- readRDS(file.path(models, "m2.tv_R2.rds"))


# Summary
summary(m2.tv)

```


Let's also check the visuals

```{r h1.m1 check, echo=TRUE, message=FALSE, warning=FALSE}

plot(m2.tv)
# comments

plot(conditional_effects(m2.tv), points = TRUE)
# almost no conditional effects

pp_check(m2.tv, type = "dens_overlay")
# seems better

pp_check(m2.tv, type = "error_scatter_avg")
# still has a correlation

m2.tv_R2
# accounts for 2 percent of the variance.

```

We are still not acknowledging some structures of the data to the model. There is some variance coming from XYZ. So we want to add it into the model too

## Model 3 - lognormal with random effects

```{r h1.m1 model, eval=FALSE, message=FALSE, warning=FALSE}

m3.tv <- brm(
  variability_shifted ~ generation_number_c + (1 | participantID) + (1 | gesture) + (1 | chainID), 
  data = data,
  family = lognormal(),  # Normal distribution for continuous entropy
  chains = 4, iter = 4000, warmup = 2000, cores = 4
)

# Add criterions for later diagnostics
m3.tv <- add_criterion(m3.tv, criterion = c("loo", "waic"))

# Calculate also variance explained (R^2)
m3.tv_R2 <- bayes_R2(m3.tv)

# Save both as objects
saveRDS(m3.tv, file.path(models, "m3.tv.rds"))
saveRDS(m3.tv_R2, file.path(models, "m3.tv_R2.rds"))


beep(5)

```

And once again we do all over the whole procedure

```{r h1.m1 sum, echo=TRUE, message=FALSE, warning=FALSE}

m3.tv <- readRDS(file.path(models, "m3.tv.rds"))
m3.tv_R2 <- readRDS(file.path(models, "m3.tv_R2.rds"))


# Summary
summary(m3.tv)

```



Let's also check the visuals

```{r h1.m1 check, echo=TRUE, message=FALSE, warning=FALSE}

plot(m3.tv)

#

plot(conditional_effects(m3.tv), points = TRUE)
# almost no effect

pp_check(m3.tv, type = "dens_overlay")
# seems like a pretty good overlay

pp_check(m3.tv, type = "error_scatter_avg")
# there is some correlation but also lots of blobs

m3.tv_R2
# explains 43 percent of the variance

```
## MODEL FOUR: (Investigate other fixed effects)
In this model, we investigate the effects of Age, Extroversion, and Gender. Thus, we begin by plotting the relationships between them. 

Age:
```{r}

ggplot(data, aes(x = Age, y = total_body_variability2D)) +
  geom_point(alpha = 0.5) +  # Scatter plot with transparency
  geom_smooth(method = "lm", color = "blue", se = TRUE) +  # Linear trend line with confidence interval
  labs(x = "Age", 
       y = "Temporal Variability", 
       title = "Linear Relationship between Age and Gesture space") +
  theme_minimal()

```
Extroversion
```{r}

ggplot(data, aes(x = Extroversion, y = total_body_variability2D)) +
  geom_point(alpha = 0.5) +  # Scatter plot with transparency
  geom_smooth(method = "lm", color = "blue", se = TRUE) +  # Linear trend line with confidence interval
  labs(x = "Extroversion", 
       y = "Temporal Variability", 
       title = "Linear Relationship between Extroversion and Temporal Variability") +
  theme_minimal()

```
Gender
```{r}

ggplot(data, aes(x = Gender, y = total_body_variability2D)) +
  geom_point(alpha = 0.5) +  # Scatter plot with transparency
  geom_smooth(method = "lm", color = "blue", se = TRUE) +  # Linear trend line with confidence interval
  labs(x = "Gender", 
       y = "Temporal Variability", 
       title = "Linear Relationship between Gender and Temporal Variability") +
  theme_minimal()

```

```{r h1.m1 model, eval=FALSE, message=FALSE, warning=FALSE}

m4.tv <- brm(
  variability_shifted ~ generation_number_c + Age + Extroversion + (1 | participantID) + (1 | gesture) + (1 | chainID), 
  data = data,
  family = lognormal(),  # Normal distribution for continuous entropy
  chains = 4, iter = 2000, warmup = 1000, cores = 4
)

# Add criterions for later diagnostics
m4.tv <- add_criterion(m4.gs, criterion = c("loo", "waic"))

# Calculate also variance explained (R^2)
m4.tv_R2 <- bayes_R2(m4.tv)

# Save both as objects
saveRDS(m4.tv, file.path(models, "m4.tv.rds"))
saveRDS(m4.tv_R2, file.path(models, "m4.tv_R2.rds"))


beep(5)

m4.tv <- readRDS(file.path(models, "m4.tv.rds"))
m4.tv_R2 <- readRDS(file.path(models, "m4.tv_R2.rds"))


# Summary
summary(m4.tv)

```
Let's also check visuals
```{r h1.m1 check, echo=TRUE, message=FALSE, warning=FALSE}

plot(m4.tv)

#

plot(conditional_effects(m4.tv), points = TRUE)
# almost no correlation

pp_check(m4.tv, type = "dens_overlay")
# good overlay

pp_check(m4.tv, type = "error_scatter_avg")
# some correlation but also some blobbing


m4.tv_R2
# explains 65 percent of the variance.
```


### Converting to original scale

We also have to remember that model with lognormal distribution outputs all coefficients (intercept, etc) on logscale, not the natural one

The following code converts the mean estimates to original scale

This is for all predictors (except concept and participant)
```{r h1.m6 converting5, message=FALSE, warning=FALSE}

# Extract posterior samples
posterior_samples <- as_draws_df(m3.gs)
alpha_samples <- posterior_samples$b_Intercept

# Initialize effect list
effect_list <- list()

# Helper function to calculate summary statistics
get_effect_summary <- function(effect_samples) {
  mean_effect <- mean(effect_samples)
  se_effect <- sd(effect_samples)
  ci_effect <- quantile(effect_samples, c(0.025, 0.975))
  post_prob <- mean(effect_samples > 0)
  c(mean = mean_effect, 
    se = se_effect, 
    lower_ci = ci_effect[1], 
    upper_ci = ci_effect[2], 
    post_prob = post_prob)
}

# GENERATION NUMBER (centered continuous)
if ("b_generation_number_c" %in% colnames(posterior_samples)) {
  beta_generation <- posterior_samples$b_generation_number_c
  effect_list$Generation_number_c <- get_effect_summary(exp(alpha_samples + beta_generation) - exp(alpha_samples))
}

if ("b_Age" %in% colnames(posterior_samples)) {
  beta_generation <- posterior_samples$b_Age
  effect_list$Age <- get_effect_summary(exp(alpha_samples + beta_generation) - exp(alpha_samples))
}

if ("b_Extroversion" %in% colnames(posterior_samples)) {
  beta_generation <- posterior_samples$b_Extroversion
  effect_list$Extroversion <- get_effect_summary(exp(alpha_samples + beta_generation) - exp(alpha_samples))
}

# Convert to a nicely formatted data frame
effect_df <- do.call(rbind, effect_list)

# View effects
effect_df

```

## Diagnostics I

These are diagnostics that will help us to assess and validate each models in terms of their predictive power

```{r h1 diagnostics I, include=FALSE, message=FALSE, warning=FALSE}

model_list <- list() # here we list all the models

r2_list <- list() # here we list all r2 objects

# Gillian (me) ADDED THIS MYSELF BECAUSE THE LISTS SEEMED TO BE EMPTY
model_list[["m1.gs"]] <- m1.gs
model_list[["m2.gs"]] <- m2.gs
model_list[["m3.gs"]] <- m3.gs
model_list[["m4.gs"]] <- m4.gs

# Compute and store Bayesian R^2 values
r2_list[["m1.gs"]] <- bayes_R2(m1.gs)
r2_list[["m2.gs"]] <- bayes_R2(m2.gs)
r2_list[["m3.gs"]] <- bayes_R2(m3.gs)
r2_list[["m4.gs"]] <- bayes_R2(m4.gs)
```

### Rhat

```{r h1 rhat I, message=FALSE, warning=FALSE}

# Extract R-hat values for each model
rhat_list <- lapply(model_list, function(model) {
  rhat_values <- rhat(model)
  data.frame(model = deparse(substitute(model)), 
             max_rhat = max(rhat_values), 
             min_rhat = min(rhat_values))
})

# Combine and inspect
do.call(rbind, rhat_list)

```


### ESS

Effective sample size tells how many independent samples the model has effectively drawn from the PD. Low ESS suggests autocorrelation (i.e., sample explores one part of posterior), while high ESS means good mix

```{r h1 ess I, message=FALSE, warning=FALSE}

# Extract n_eff values for each model
neff_ratio_list <- lapply(model_list, function(model) {
  neff_values <- neff_ratio(model)              # Here we calculate ratio (not the raw number of effective samples)
  data.frame(model = deparse(substitute(model)), 
             min_neff = min(neff_values), 
             max_neff = max(neff_values),
             mean_neff = mean(neff_values))
               
})

# Combine and inspect
do.call(rbind, neff_ratio_list)

```

Now you can look at the actuall ESS of some models

```{r h1 ess I.I, message=FALSE, warning=FALSE}

effective_sample(h1.m6c) 


```



### LOO & WAIC

Leave-one-out (loo) validation
```{r h1 loo I, message=FALSE, warning=FALSE}

l <- loo_compare(#here you list your models, criterion = "loo")

print(l, simplify = F)

```
elpd_loo: This is the expected log pointwise predictive density for LOO. Higher values indicate a better fit to the data.

se_elpd_loo: The standard error of the elpd_loo, representing uncertainty in the model’s predictive fit according to LOO.

looic: The LOO Information Criterion, which is similar to waic but based on leave-one-out cross-validation. Lower values are better.

p_loo: The effective number of parameters according to LOO, indicating the model’s complexity.

se_p_loo: The standard error of p_loo, representing uncertainty around the effective number of parameters.

So lognormal seems the best. 


Information criterion (WAIC)
```{r h1 waic I, message=FALSE, warning=FALSE}

w <- loo_compare(#here you list your models, criterion = "waic")

print(w, simplify = F)

# see Solomon Kurz
cbind(waic_diff = w[,1] * -2,
      se = w[,2] * 2)

```
elpd_waic (expected log pointwise predictive density for WAIC): This represents the model's predictive fit to the data. Higher values indicate a better fit.

se_elpd_waic (standard error of elpd_waic): Measures uncertainty around the elpd_waic estimate.

waic: The Widely Applicable Information Criterion, a measure of model fit where lower values indicate a better fit.

se_waic (standard error of WAIC): Uncertainty around the WAIC estimate.

elpd_diff: The difference in the elpd_waic between the model in question and the baseline model (fit_eff_2, which has elpd_diff of 0). A negative value indicates that the model fits worse than fit_eff_2.

se_diff: The standard error of the elpd_diff, indicating how much uncertainty there is in the difference in predictive performance.

p_waic: The number of effective parameters in the model (related to model complexity). Lower values indicate simpler models, and higher values suggest more complexity.

Plot the comparison
```{r h1 waic plot, echo=FALSE, message=FALSE, warning=FALSE}

w[, 7:8] %>% 
  data.frame() %>% 
  rownames_to_column("model_name") %>% 
  mutate(model_name = fct_reorder(model_name, waic, .desc = T)) %>% 
  
  ggplot(aes(x = waic, y = model_name, 
             xmin = waic - se_waic, 
             xmax = waic + se_waic)) +
  geom_pointrange(color = carto_pal(7, "BurgYl")[7], 
                  fill = carto_pal(7, "BurgYl")[5], shape = 21) +
  labs(title = "WAIC plot",
       x = NULL, y = NULL) +
  theme(axis.ticks.y = element_blank())

```

```{r h1 weights, message=FALSE, warning=FALSE}

model_weights(#here again you list your models, weights = "waic") %>% 
  round(digits = 2)

```


From this, you should be more confident in saying, we choose this model and the model says there is XY effect.

You can reuse the same model for the rest of the features - as long as you are within one question type (so here relation between a feature and generation)

Now onto next question

# Questions about age-gesture space etc. (see model four of each section)


# Questions about distance (rate of evolution)

# 

#tried to center the distance data even though I don't really know whether or not we need to. 
```{r}
data$total_distance_c <- data$total_distance - median(range(data$total_distance, na.rm = TRUE), na.rm = TRUE)

min_val <- min(data$total_distance_c, na.rm = TRUE)

if (min_val <= 0) {
  shift_constant <- abs(min_val) + 1e-6  # small buffer to avoid exact zero
  data$total_distance_c <- data$total_distance_c + shift_constant
} else {
  shift_constant <- 0  # already positive
}

hist(data$total_distance_c)
```

```{r}
m1.dist <- brm(
  total_distance_c ~ generation_number_c + diff_in_age + diff_in_extrovet + (1 | participantID) + (1 | gesture) + (1 | chainID), 
  data = data,
  family = lognormal(),  # Normal distribution for continuous entropy
  chains = 4, iter = 2000, warmup = 1000, cores = 4
)

m1.dist <- add_criterion(m1.dist, criterion = c("loo", "waic"))

# Calculate also variance explained (R^2)
m1.dist_R2 <- bayes_R2(m1.dist)

# Save both as objects
saveRDS(m1.dist, file.path(models, "m1.dist.rds"))
saveRDS(m1.dist_R2, file.path(models, "m1.dist_R2.rds"))


beep(5)

```
 
And we do the same procedure

```{r h1.m1 sum, echo=TRUE, message=FALSE, warning=FALSE}

m1.dist <- readRDS(file.path(models, "m1.dist.rds"))
m1.dist_R2 <- readRDS(file.path(models, "m1.dist_R2.rds"))


# Summary
summary(m1.dist)

```


Let's also check the visuals

```{r h1.m1 check, echo=TRUE, message=FALSE, warning=FALSE}

plot(m1.dist)
# comments

plot(conditional_effects(m1.dist), points = TRUE)
# some conditional effects it seems like

pp_check(m1.dist, type = "dens_overlay")
# seems better

pp_check(m1.dist, type = "error_scatter_avg")
# no corrleation

m1.dist_R2
# accounts for 46 percent of the variance.

```
