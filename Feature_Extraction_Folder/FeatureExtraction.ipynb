{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Feature_Extraction_Folder\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import pyentrp\n",
    "\n",
    "import pyentrp\n",
    "\n",
    "from pyentrp import entropy as ent\n",
    "\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "\n",
    "# get relevent folders\n",
    "curfolder = os.getcwd()\n",
    "print(curfolder)\n",
    "\n",
    "flesh_folder = os.path.dirname(curfolder)\n",
    "motion_processing = flesh_folder + '/Motion_Processing_Folder'\n",
    "\n",
    "mtfolder = motion_processing + '/TS_movement/'\n",
    "print(mtfolder)\n",
    "\n",
    "mtfiles = glob.glob(mtfolder + '*.csv')\n",
    "\n",
    "demographics = curfolder + \"/demographicsProcessed.csv\"\n",
    "\n",
    "which_arm = curfolder + '/which_arm.csv'\n",
    "which_arm = pd.read_csv(which_arm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the total movement of a key point given inputed key point and motion processed file\n",
    "# This function is specifically relevent if you wish to calculate each side's arm movement seprately\n",
    "def gesturespace2D(sample, joint, side, movement_type): \n",
    "    #get the subdf for where there is only movement for that tier. \n",
    "    fileID = sample[\"fileID\"][0]\n",
    "    total_movement = int(0)\n",
    "    movement_sample = sample[sample[movement_type] == 'movement']\n",
    "    # if the movement type is arms, then check whether the left or right arm has movement and output accordingly. \n",
    "    if movement_type == 'arms':\n",
    "        if side == \"LEFT_\": \n",
    "            arm = 'l'\n",
    "        if side == \"RIGHT_\":\n",
    "            arm = 'r'\n",
    "        # if that specific arm has no movement, return zero\n",
    "        if not which_arm.loc[which_arm['fileID'] == fileID, 'arms'].isin([arm, 'b']).any():\n",
    "            return 0\n",
    "        # if that specific arm does have movement, return the movement\n",
    "    # if it is no arms, return the movement\n",
    "    if movement_sample.empty:\n",
    "        return 0\n",
    "    else:\n",
    "        X_std = np.std(movement_sample[\"X_\" + side + joint])\n",
    "        Y_std = np.std(movement_sample[\"Y_\" + side + joint])\n",
    "        total_movement = X_std + Y_std # FLAG: hm, should this really be a sumation or rather squared suM??\n",
    "        return total_movement\n",
    "\n",
    "\n",
    "# returns the total entropy of a key point given inputed key point and motion processed file\n",
    "# This function is specifically relevent if you wish to calculate each side's arm movement seprately\n",
    "def entropyts2D(sample, joint, side, movement_type):\n",
    "    fileID = sample[\"fileID\"][0]\n",
    "    movement_sample = sample[sample[movement_type] == \"movement\"]\n",
    "    if movement_type == 'arms':\n",
    "        if side == \"LEFT_\": \n",
    "            arm = 'l'\n",
    "        if side == \"RIGHT_\":\n",
    "            arm = 'r'\n",
    "        # if that specific arm has no movement, return zero\n",
    "        if not which_arm.loc[which_arm['fileID'] == fileID, 'arms'].isin([arm, 'b']).any():\n",
    "            return 0\n",
    "        # if that specific arm does have movement, return the movement\n",
    "    if movement_sample.empty:\n",
    "        return 0\n",
    "    else:\n",
    "        speed_ts = (movement_sample[side + joint + \"_speed2D\"]).values\n",
    "        sample_entropy = ent.sample_entropy(speed_ts, 1)\n",
    "        return sample_entropy\n",
    "    \n",
    "# returns the total entropy of a key point given inputed key point and motion processed file\n",
    "# This function is specifically relevent if you wish to calculate arm movement using the combined timeseries\n",
    "def entropyts2Daggregated(sample, joint, movement_type):\n",
    "    fileID = sample[\"fileID\"][0]\n",
    "    movement_sample = sample[sample[movement_type] == \"movement\"]\n",
    "        # if that specific arm does have movement, return the movement\n",
    "    if movement_sample.empty:\n",
    "        return 0\n",
    "    else:\n",
    "        speed_ts = (movement_sample[joint + \"_speed2D\"]).values\n",
    "        sample_entropy = ent.sample_entropy(speed_ts, 1)\n",
    "        return sample_entropy\n",
    "\n",
    "\n",
    "# returns the total temporal variability of a key point given inputed key point and motion processed file\n",
    "# This function is specifically relevent if you wish to calculate each side's arm movement seprately\n",
    "def temporal_variability_function2D(sample, joint, side, movement_type):\n",
    "    fileID = sample[\"fileID\"][0]\n",
    "    #get the subdf for where there is only movement for that tier. \n",
    "    movement_sample = sample[sample[movement_type] == \"movement\"]\n",
    "    # calculate each arm separately if there is arm movement\n",
    "    if movement_type == 'arms':\n",
    "        if side == \"LEFT_\": \n",
    "            arm = 'l'\n",
    "        if side == \"RIGHT_\":\n",
    "            arm = 'r'\n",
    "        # if that specific arm has no movement, return zero\n",
    "        if not which_arm.loc[which_arm['fileID'] == fileID, 'arms'].isin([arm, 'b']).any():\n",
    "            return 0\n",
    "    if movement_sample.empty:\n",
    "        return 0\n",
    "    else:\n",
    "        # find the average speed of the speed time series\n",
    "        speed_ts = (movement_sample[side + joint + \"_speed2D\"]).to_numpy()\n",
    "        avg_height = np.mean(speed_ts)\n",
    "        # calculate the peaks in the speed timeseries with the average speed as the min peak height.\n",
    "        peaks, _ = scipy.signal.find_peaks(speed_ts, avg_height)\n",
    "        # determine if there are more than two peaks\n",
    "        if len(peaks) > 2:\n",
    "            diff_in_peaks = np.empty(len(peaks)-1)\n",
    "            # calulcate all the amounts of time between peaks\n",
    "            for i in range(len(peaks)-1): \n",
    "                current_peak = sample.loc[peaks[i], \"time\" ]\n",
    "                next_peak = sample.loc[peaks[i+1], \"time\" ]\n",
    "                time_between_peaks = next_peak - current_peak\n",
    "                diff_in_peaks[i] = time_between_peaks\n",
    "            # find the standard deviation in peak distance\n",
    "            temporal_variability= np.std(diff_in_peaks)\n",
    "            return temporal_variability\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "\n",
    "# returns the total temporal variability of a key point given inputed key point and motion processed file\n",
    "# This function is specifically relevent if you wish to calculate arm movement using the combined timeseries\n",
    "def temporal_variability_function2Daggregated(sample, joint, movement_type):\n",
    "    fileID = sample[\"fileID\"][0]\n",
    "    movement_sample = sample[sample[movement_type] == \"movement\"]\n",
    "    if movement_sample.empty:\n",
    "        return 0\n",
    "    else:\n",
    "        # find the average speed of the speed time series\n",
    "        speed_ts = (movement_sample[joint + \"_speed2D\"]).to_numpy()\n",
    "        avg_height = np.mean(speed_ts)\n",
    "        # calculate the peaks in the speed timeseries with the average speed as the min peak height.\n",
    "        peaks, _ = scipy.signal.find_peaks(speed_ts, avg_height)\n",
    "        # determine if there are more than two peaks\n",
    "        if len(peaks) > 2:\n",
    "            diff_in_peaks = np.empty(len(peaks)-1)\n",
    "            # calulcate all the amounts of time between peaks\n",
    "            for i in range(len(peaks)-1): \n",
    "                current_peak = sample.loc[peaks[i], \"time\" ]\n",
    "                next_peak = sample.loc[peaks[i+1], \"time\" ]\n",
    "                time_between_peaks = next_peak - current_peak\n",
    "                diff_in_peaks[i] = time_between_peaks\n",
    "            # find the standard deviation in peak distance\n",
    "            temporal_variability= np.std(diff_in_peaks)\n",
    "            return temporal_variability\n",
    "        else:\n",
    "            return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add survey data to the features dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates the dataframe of features\n",
    "featuredf = pd.DataFrame()\n",
    "\n",
    "# gets the survey information\n",
    "demographics_read = pd.read_csv(demographics) \n",
    "\n",
    "# adds survey columns to the features csv file\n",
    "columns_to_add = demographics_read.columns\n",
    "for col in columns_to_add:\n",
    "    featuredf[col] = pd.NA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main For Loop For Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch3_g12_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch2_g3_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch1_g0_compr.eaf.csv\n",
      "no matching demographics rowfor0\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch1_g16_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch2_g10_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch1_g0_compr.eaf.csv\n",
      "no matching demographics rowfor0\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch2_g17_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch2_g6_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch1_g5_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch2_g6_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch2_g14_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch1_g4_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch1_g12_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch1_g4_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch2_g7_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch3_g16_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch2_g2_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch1_g1_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch2_g2_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch2_g13_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch2_g18_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch3_g18_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch1_g20_compr.eaf.csv\n",
      "no matching demographics rowfor20\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch3_g13_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch3_g5_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch1_g15_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch2_g11_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch1_g2_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch1_g19_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch2_g4_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch3_g14_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch1_g6_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch1_g11_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch2_g15_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch3_g1_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch3_g17_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch3_g9_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch3_g10_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch2_g8_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch1_g1_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch2_g12_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch1_g16_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch3_g6_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch3_g10_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch1_g9_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch3_g17_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch2_g7_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch3_g14_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch3_g2_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch2_g16_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch1_g12_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch1_g5_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch1_g19_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch2_g3_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch3_g13_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch1_g20_compr.eaf.csv\n",
      "no matching demographics rowfor20\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch3_g18_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch2_g13_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch1_g3_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch2_g18_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch1_g3_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch1_g15_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch3_g11_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch2_g5_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch3_g9_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch1_g6_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch2_g5_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch2_g14_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch3_g15_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch2_g4_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch1_g11_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch1_g7_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch3_g8_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch1_g18_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch3_g8_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch2_g17_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch1_g7_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch2_g10_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch2_g1_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch1_g2_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch2_g1_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch3_g16_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch3_g2_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch1_g12_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch2_g16_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch3_g2_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch3_g7_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch1_g8_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch1_g9_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch3_g6_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch1_g16_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch3_g6_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch2_g12_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch1_g9_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch2_g19_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch3_g12_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch2_g20_compr.eaf.csv\n",
      "no matching demographics rowfor40\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch3_g3_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch1_g13_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch3_g20_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch1_g18_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch3_g8_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch3_g15_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch1_g7_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch2_g15_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch3_g19_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch2_g9_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch1_g14_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch2_g1_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch2_g11_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch3_g4_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch3_g11_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch1_g3_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch2_g18_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch1_g17_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch2_g5_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch1_g10_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch2_g16_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch3_g3_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch3_g16_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch1_g4_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch1_g10_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch2_g2_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch1_g17_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch1_g8_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch1_g14_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch3_g19_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch3_g12_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch1_g0_compr.eaf.csv\n",
      "no matching demographics rowfor0\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch3_g7_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch2_g12_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch3_g20_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch1_g13_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch2_g6_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch2_g20_compr.eaf.csv\n",
      "no matching demographics rowfor40\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch1_g18_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch3_g1_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch2_g15_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch3_g1_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch1_g11_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch3_g15_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch2_g19_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch2_g8_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch3_g4_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch2_g8_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch3_g11_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch2_g11_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch1_g15_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch3_g5_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch3_g5_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch2_g9_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch3_g18_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch1_g12_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch2_g7_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch3_g13_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch1_g1_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch3_g18_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch2_g13_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch3_g6_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch1_g15_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch1_g9_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch2_g3_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch1_g16_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch1_g11_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch3_g2_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch2_g17_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch3_g17_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch1_g5_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch3_g20_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch3_g1_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch3_g4_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch3_g19_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch2_g8_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch3_g10_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch2_g10_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch1_g14_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch3_g4_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch3_g5_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch2_g9_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch2_g9_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch2_g18_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch1_g20_compr.eaf.csv\n",
      "no matching demographics rowfor20\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch2_g14_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch1_g10_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch3_g14_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch1_g19_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch3_g2_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch1_g8_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch2_g18_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch3_g7_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch2_g13_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch3_g13_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch3_g7_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch1_g8_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch1_g9_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch3_g6_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch3_g3_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch3_g17_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch3_g3_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch1_g13_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch2_g17_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch2_g20_compr.eaf.csv\n",
      "no matching demographics rowfor40\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch2_g4_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch1_g11_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch1_g16_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch2_g19_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch3_g5_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch2_g10_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch3_g10_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch1_g2_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch1_g15_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch3_g18_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch1_g20_compr.eaf.csv\n",
      "no matching demographics rowfor20\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch3_g14_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch1_g6_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch2_g14_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch3_g1_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch1_g19_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch1_g12_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch3_g9_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch2_g2_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch3_g12_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch3_g3_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch1_g18_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch1_g4_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch2_g17_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch1_g13_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch3_g15_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch3_g16_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch2_g6_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch1_g8_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch3_g11_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch2_g13_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch1_g17_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch1_g0_compr.eaf.csv\n",
      "no matching demographics rowfor0\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch3_g7_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch1_g20_compr.eaf.csv\n",
      "no matching demographics rowfor20\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch2_g11_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch1_g3_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch2_g16_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch1_g6_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch1_g19_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch3_g9_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch2_g5_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch3_g14_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch3_g9_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch1_g10_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch1_g6_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch1_g7_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch2_g15_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch2_g4_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch2_g4_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch3_g20_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch3_g8_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch2_g20_compr.eaf.csv\n",
      "no matching demographics rowfor40\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch1_g2_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch1_g14_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch3_g10_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch2_g1_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch3_g19_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch2_g12_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch1_g2_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch1_g0_compr.eaf.csv\n",
      "no matching demographics rowfor0\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch2_g12_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch2_g3_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch2_g3_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch1_g13_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch1_g5_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch3_g17_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch2_g6_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch2_g15_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch1_g5_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch2_g7_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch2_g7_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch2_g16_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch1_g4_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch2_g11_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch1_g1_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch2_g2_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch3_g13_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch1_g1_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch1_g17_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch2_g9_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch3_g11_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch2_g1_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch3_g16_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch3_g8_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch1_g10_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch2_g14_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch1_g7_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch2_g5_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch3_g15_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch2_g20_compr.eaf.csv\n",
      "no matching demographics rowfor40\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch3_g20_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch1_g18_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/leise_g_ch3_g4_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch1_g3_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch1_g14_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/rennen_g_ch2_g10_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/Donner_g_ch2_g19_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/kalt_g_ch3_g12_compr.eaf.csv\n",
      "/Users/gillianrosenberg/Documents/GitHub/FLESH_IteratedLearning/Motion_Processing_Folder/TS_movement/langsam_g_ch3_g19_compr.eaf.csv\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "# Loop through all files and extract all gesture features\n",
    "for file in mtfiles:\n",
    "    print(file)\n",
    "    sample = pd.read_csv(file)\n",
    "\n",
    "    # get the fileID \n",
    "    featuredf.loc[count, \"fileID\"] = (sample[\"fileID\"])[0]\n",
    "\n",
    "    # get the chainID and the participantID and generation number\n",
    "    featuredf.loc[count, \"chainID\"] = sample[\"participantID\"][0]\n",
    "    chainID = featuredf[\"chainID\"][count]\n",
    "    split_string = chainID.split('ch')[1]\n",
    "    split_string = split_string.split('g')\n",
    "    chain_num = split_string[0]\n",
    "    gen_num = split_string[1]\n",
    "    featuredf.loc[count, \"generation_number\"] = int(gen_num)\n",
    "    featuredf.loc[count, \"chain_number\"] = int(chain_num)\n",
    "    participantID = (int(chain_num) - 1) * 20 + int(gen_num)\n",
    "    gesture = featuredf.loc[count, 'fileID'].split(\"_\")[0]\n",
    "    gesture_chain = (re.split(r\"_g\\d+\", featuredf.loc[count, 'fileID'])[0])\n",
    "    featuredf.loc[count, \"participantID\"] = participantID\n",
    "    featuredf.loc[count, \"gesture\"] = gesture\n",
    "    featuredf.loc[count, \"gesture_chain\"] = gesture_chain\n",
    "\n",
    "    # get the demographic information from the survey and puts it in correct row in featuredf \n",
    "    matching_rows = demographics_read[demographics_read[\"participantID\"] == int(participantID)]\n",
    "    if len(matching_rows) > 0:\n",
    "        demographic_row = matching_rows.iloc[0]\n",
    "        matching_row = demographics_read[demographics_read[\"participantID\"] == int(participantID)]\n",
    "        featuredf.loc[count, columns_to_add] = matching_row.iloc[0].values\n",
    "    else:\n",
    "        print(\"no matching demographics row\" + \"for\" + str(participantID))\n",
    "\n",
    "    #Get the gesture space measures\n",
    "    #left arm\n",
    "    featuredf.loc[count, \"left_index_space2D\"] = gesturespace2D(sample, \"INDEX\", \"LEFT_\", \"arms\")\n",
    "    featuredf.loc[count, \"left_wrist_space2D\"] = gesturespace2D(sample, \"WRIST\", \"LEFT_\", \"arms\")\n",
    "    featuredf.loc[count, \"left_elbow_space2D\"] = gesturespace2D(sample, \"ELBOW\", \"LEFT_\", \"arms\") \n",
    "    featuredf.loc[count, \"total_left_arm_space2D\"] = featuredf.loc[count, \"left_index_space2D\"] + featuredf.loc[count, \"left_wrist_space2D\"] + featuredf.loc[count, \"left_elbow_space2D\"]## FLAG: hm, can we discuss this in flesh meeting whether summations of three keypoints is really the whole space - maybe wrist only would be better\n",
    "\n",
    "    # right arm\n",
    "    featuredf.loc[count, \"right_index_space2D\"] = gesturespace2D(sample, \"INDEX\", \"RIGHT_\", \"arms\")\n",
    "    featuredf.loc[count, \"right_wrist_space2D\"] = gesturespace2D(sample, \"WRIST\", \"RIGHT_\", \"arms\")\n",
    "    featuredf.loc[count, \"right_elbow_space2D\"] = gesturespace2D(sample, \"ELBOW\", \"RIGHT_\", \"arms\")\n",
    "    featuredf.loc[count, \"total_right_arm_space2D\"] = featuredf.loc[count, \"right_index_space2D\"] + featuredf.loc[count, \"right_wrist_space2D\"] + featuredf.loc[count, \"right_elbow_space2D\"]\n",
    "\n",
    "    # left leg\n",
    "    featuredf.loc[count, \"left_ankle_space2D\"] = gesturespace2D(sample, \"ANKLE\", \"LEFT_\", \"lower_body\")\n",
    "    featuredf.loc[count, \"left_knee_space2D\"] = gesturespace2D(sample, \"KNEE\", \"LEFT_\", \"lower_body\")\n",
    "    featuredf.loc[count, \"left_hip_space2D\"] = gesturespace2D(sample, \"HIP\", \"LEFT_\", \"lower_body\")\n",
    "    featuredf.loc[count, \"total_left_leg_space2D\"] = featuredf.loc[count, \"left_ankle_space2D\"] + featuredf.loc[count, \"left_knee_space2D\"] + featuredf.loc[count, \"left_hip_space2D\"]\n",
    "\n",
    "    # right leg\n",
    "    featuredf.loc[count, \"right_ankle_space2D\"] = gesturespace2D(sample, \"ANKLE\", \"RIGHT_\", \"lower_body\")\n",
    "    featuredf.loc[count, \"right_knee_space2D\"] = gesturespace2D(sample, \"KNEE\", \"RIGHT_\", \"lower_body\")\n",
    "    featuredf.loc[count, \"right_hip_space2D\"] = gesturespace2D(sample, \"HIP\", \"RIGHT_\", \"lower_body\")\n",
    "    featuredf.loc[count, \"total_right_leg_space2D\"] = featuredf.loc[count, \"right_ankle_space2D\"] + featuredf.loc[count, \"right_knee_space2D\"] + featuredf.loc[count, \"right_hip_space2D\"]\n",
    "\n",
    "    # head (nose)\n",
    "    featuredf.loc[count, \"nose_space2D\"] = gesturespace2D(sample, \"NOSE\", \"\", \"head_mov\")\n",
    "    featuredf.loc[count, \"total_head_space2D\"] = featuredf.loc[count, \"nose_space2D\"]\n",
    "\n",
    "    # total gesture space\n",
    "    featuredf.loc[count, \"total_gesture_space2D\"] = featuredf.loc[count, \"total_left_arm_space2D\"] + featuredf.loc[count, \"total_right_arm_space2D\"] + featuredf.loc[count, \"total_left_leg_space2D\"] + featuredf.loc[count, \"total_right_leg_space2D\"] + featuredf.loc[count, 'total_head_space2D']\n",
    "\n",
    "    # get the entropy for wrist, knee, and ankle. \n",
    "    #wrist entropy\n",
    "    featuredf.loc[count, \"right_wrist_entropy2D\"] = entropyts2D(sample, \"WRIST\", \"RIGHT_\", \"arms\")\n",
    "    featuredf.loc[count, \"left_wrist_entropy2D\"] = entropyts2D(sample, \"WRIST\", \"LEFT_\", \"arms\")\n",
    "\n",
    "    #knees enropy\n",
    "    featuredf.loc[count, \"right_knee_entropy2D\"] = entropyts2D(sample, \"KNEE\", \"RIGHT_\", \"lower_body\")\n",
    "    featuredf.loc[count, \"left_knee_entropy2D\"] = entropyts2D(sample, \"KNEE\", \"LEFT_\", \"lower_body\")\n",
    "\n",
    "    #ankle enropy\n",
    "    featuredf.loc[count, \"right_ankle_entropy2D\"] = entropyts2D(sample, \"ANKLE\", \"RIGHT_\", \"lower_body\")# FLAG: why both ankle and knee? while for hands we have just wrist\n",
    "    featuredf.loc[count, \"left_ankle_entropy2D\"] = entropyts2D(sample, \"ANKLE\", \"LEFT_\", \"lower_body\")\n",
    "\n",
    "    #total_entropy\n",
    "    featuredf.loc[count, \"total_body_entropy2D\"] = featuredf.loc[count, \"left_ankle_entropy2D\"]+ featuredf.loc[count, \"right_ankle_entropy2D\"] + featuredf.loc[count, \"left_knee_entropy2D\"] +featuredf.loc[count, \"right_knee_entropy2D\"] + featuredf.loc[count, \"left_wrist_entropy2D\"] + featuredf.loc[count, \"right_wrist_entropy2D\"]\n",
    "    \n",
    "    #total_entropy using aggregated time series\n",
    "    featuredf.loc[count, \"total_body_entropy2Daggregated\"] = entropyts2Daggregated(sample, \"ARMTOTAL\", \"arms\")\n",
    "\n",
    "    # temporal variability\n",
    "    #wrist\n",
    "    featuredf.loc[count, \"right_wrist_variability2D\"] = temporal_variability_function2D(sample, \"WRIST\", \"RIGHT_\", \"arms\")\n",
    "    featuredf.loc[count, \"left_wrist_variability2D\"] = temporal_variability_function2D(sample, \"WRIST\", \"LEFT_\", \"arms\")\n",
    "\n",
    "    #total variability\n",
    "    featuredf.loc[count, 'total_body_variability2D'] = featuredf.loc[count, \"right_wrist_variability2D\"] + featuredf.loc[count, \"left_wrist_variability2D\"]\n",
    "    \n",
    "    #total variability using aggreagated time series\n",
    "    featuredf.loc[count, 'total_body_variability2Daggregated'] = temporal_variability_function2Daggregated(sample, 'ARMTOTAL', \"arms\")\n",
    "    count = count +1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code to plot the features for each chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14ebb12e0>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samplechainD = featuredf[featuredf['fileID'].str.contains(\"Donner_g_ch1\")]\n",
    "plt.plot(samplechainD['generation_number'], samplechainD['total_body_entropy2Daggregated'], marker='o', linestyle='')\n",
    "plt.plot(samplechainD['generation_number'], samplechainD['total_body_entropy2D'], marker='o', linestyle='')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saves the df to the feature extraction file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[\"feature_extraction\"] = featuredf\n",
    "globals()[\"feature_extraction\"].to_csv(os.path.join(curfolder, f'{\"feature_extraction_with2d\"}.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flesh_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
